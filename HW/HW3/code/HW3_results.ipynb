{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T14:55:18.328703Z",
     "start_time": "2023-12-02T14:55:17.506836Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# solving racetrack using reinforcement learning\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a965349e07c8016d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T14:56:05.708020Z",
     "start_time": "2023-12-02T14:56:05.668087Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the racetrack\n",
    "# 0: empty\n",
    "# 1: obstacle\n",
    "# 2: start\n",
    "# 3: finish\n",
    "racetrack_map = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "  ], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30ceeda1ee94e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T14:56:06.572958Z",
     "start_time": "2023-12-02T14:56:06.389260Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the racetrack\n",
    "plt.imshow(racetrack_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc10a0ef1e53e576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T15:41:19.220256Z",
     "start_time": "2023-12-02T15:41:19.136610Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([29, 21]), 0, 0]\n",
      "[-1  0]\n"
     ]
    }
   ],
   "source": [
    "start_array = np.argwhere(racetrack_map == 2)\n",
    "print([start_array[np.random.randint(0, len(start_array))],0,0])\n",
    "action_space = np.array([\n",
    "            [-1, -1], [-1, 0], [-1, 1],\n",
    "            [0, -1], [0, 0], [0, 1],\n",
    "            [1, -1], [1, 0], [1, 1]\n",
    "        ])\n",
    "print(action_space[1])\n",
    "# np.random.randint(0, 9, size=(32, 32, 5, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f976da5831d525f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T11:26:03.679546Z",
     "start_time": "2023-12-03T11:26:03.543219Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Racetrack:\n",
    "    def __init__(self, racetrack_map, start_num):\n",
    "        self.racetrack_map = racetrack_map\n",
    "        self.height = racetrack_map.shape[0]\n",
    "        self.width = racetrack_map.shape[1]\n",
    "        self.start_array = np.argwhere(racetrack_map == 2)\n",
    "        self.finish_array = np.argwhere(racetrack_map == 3)\n",
    "        self.start_num = start_num\n",
    "        # start position is random zero velocity\n",
    "        self.start = [self.start_array[self.start_num][0],\n",
    "                      self.start_array[self.start_num][1], 0, 0]\n",
    "        # finish position is fixed\n",
    "        self.position = self.start\n",
    "        self.action_space = np.array([\n",
    "            [-1, -1], [-1, 0], [-1, 1],\n",
    "            [0, -1], [0, 0], [0, 1],\n",
    "            [1, -1], [1, 0], [1, 1]\n",
    "        ])\n",
    "        self.reward = 0\n",
    "        self.visited_cells = []\n",
    "        # random policy x y dx dy 32 * 32 * 5 * 9\n",
    "        self.policy = np.random.randint(0, 9, size=(self.height, self.width, 5, 9))\n",
    "        # Q table x y dx dy 32 * 32 * 5 * 9 * num of actions\n",
    "        self.Q = np.zeros((self.height, self.width, 5, 9, len(self.action_space)))\n",
    "        self.is_done = False\n",
    "        self.epsilon = 0.1\n",
    "        self.gamma = 0.99\n",
    "\n",
    "    def reset(self):\n",
    "        self.start = [self.start_array[self.start_num][0],\n",
    "                      self.start_array[self.start_num][1], 0, 0]\n",
    "        self.is_done = False\n",
    "\n",
    "    def get_action(self, state):\n",
    "        # soft policy greedy\n",
    "        if np.random.random() > self.epsilon:\n",
    "            return self.action_space[self.policy[state[0], state[1], state[2], state[3]]]\n",
    "        else:\n",
    "            return self.action_space[np.random.randint(0, len(self.action_space))]\n",
    "\n",
    "    def step(self, action):\n",
    "        # update position\n",
    "        self.position[0] += self.position[2]\n",
    "        self.position[1] += self.position[3]\n",
    "        self.position[2] += action[0]\n",
    "        self.position[3] += action[1]\n",
    "        # check if the car is out of the racetrack\n",
    "        # check velocity valid\n",
    "        if self.position[2] < -4:\n",
    "            self.position[2] = -4\n",
    "        elif self.position[2] > 0:\n",
    "            self.position[2] = 0\n",
    "        if self.position[3] < -4:\n",
    "            self.position[3] = -4\n",
    "        elif self.position[3] > 4:\n",
    "            self.position[3] = 4\n",
    "        # all speed are zero\n",
    "        if self.position[2] == 0 and self.position[3] == 0:\n",
    "            self.position[2] = -1\n",
    "\n",
    "\n",
    "        if self.position[0] < 0:\n",
    "            self.position[0] = 0\n",
    "            self.position[2] = 0\n",
    "        if self.position[0] >= self.height:\n",
    "            self.position[0] = self.height - 1\n",
    "            self.position[2] = 0\n",
    "        if self.position[1] < 0:\n",
    "            self.position[3] = 0\n",
    "            self.position[1] = 0\n",
    "        if self.position[1] >= self.width:\n",
    "            self.position[3] = 0\n",
    "            self.position[1] = self.width - 1\n",
    "\n",
    "        if self.position[2] == 0 and self.position[3] == 0 and self.position[0] == 0:\n",
    "            self.position[3] = 1\n",
    "        # check if the car hits the obstacle\n",
    "        if self.racetrack_map[self.position[0], self.position[1]] == 1:\n",
    "            self.reset()\n",
    "            self.reward = -5\n",
    "        # check if the car reaches the finish line\n",
    "        elif self.racetrack_map[self.position[0], self.position[1]] == 3:\n",
    "            self.reward = 50\n",
    "            self.is_done = True\n",
    "\n",
    "        else:\n",
    "            self.reward = -1\n",
    "\n",
    "        return self.position, self.reward\n",
    "\n",
    "    def render(self):\n",
    "        racetrack_map = self.racetrack_map.copy()\n",
    "        racetrack_map[self.position[0], self.position[1]] = 4\n",
    "        plt.imshow(racetrack_map)\n",
    "        plt.show()\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.position\n",
    "\n",
    "    def get_reward(self):\n",
    "        return self.reward\n",
    "\n",
    "    # update Q\n",
    "    def update_Q(self, state, action, reward, alpha, gamma):\n",
    "        # get the index of the action\n",
    "        for i in range(len(self.action_space)):\n",
    "            if np.sum(self.action_space[i] == action) == 2:\n",
    "                action_index = i\n",
    "                break\n",
    "        # get the index of the next state\n",
    "        # next_state_index = np.argwhere(self.action_space == next_state)[0][0]\n",
    "        # update Q\n",
    "        self.Q[state[0], state[1], state[2], state[3], action_index] += alpha * (\n",
    "                reward + gamma * np.max(self.Q[state[0], state[1], state[2], state[3]]) -\n",
    "                self.Q[state[0], state[1], state[2], state[3], action_index])\n",
    "\n",
    "    # update policy\n",
    "    def update_policy(self, state):\n",
    "        # get the index of the state\n",
    "        # state_index = np.argwhere(self.action_space == state)[0][0]\n",
    "        # update policy\n",
    "        self.policy[state[0], state[1], state[2], state[3]] = np.argmax(\n",
    "            self.Q[state[0], state[1], state[2], state[3]])\n",
    "        # if np.argmax(\n",
    "        #         self.Q[state[0], state[1], state[2], state[3]]) > 2:\n",
    "        #     print(np.argmax(\n",
    "        #         self.Q[state[0], state[1], state[2], state[3]]))\n",
    "\n",
    "        # plot Q for every 9 action (nine fig)\n",
    "\n",
    "\n",
    "\n",
    "    # run the car mont carlo\n",
    "    def run_mont_carlo(self, alpha, gamma, render_enable):\n",
    "        # reset the car\n",
    "        self.reset()\n",
    "        # save rewards and states\n",
    "        rewards = []\n",
    "        states = []\n",
    "        num_of_episode = 0\n",
    "        # run the car until it reaches the finish line\n",
    "        while not self.is_done:\n",
    "            num_of_episode += 1\n",
    "            if num_of_episode > 1000:\n",
    "                break\n",
    "            # get the current state\n",
    "            state = self.get_state()\n",
    "            # get the current action\n",
    "            action = self.get_action(state)\n",
    "            # save the current state copy it\n",
    "            states.append(state.copy())\n",
    "            # save the current reward\n",
    "            reward = self.get_reward()\n",
    "            rewards.append(reward)\n",
    "            # update the car\n",
    "            self.step(action)\n",
    "            if render_enable:\n",
    "                self.render()\n",
    "        if render_enable:\n",
    "            for i in range(9):\n",
    "                plt.imshow(self.Q[:, :, 1, 1, i])\n",
    "                print(i)\n",
    "                plt.show()\n",
    "        # calculate the return\n",
    "        G = 0\n",
    "        # save the return\n",
    "        returns = []\n",
    "        # calculate the return for each state\n",
    "        for i in range(len(states) - 1, -1, -1):\n",
    "            G = gamma * G + rewards[i]\n",
    "            returns.append(G)\n",
    "        # plot states on map\n",
    "        new_map = self.racetrack_map.copy()\n",
    "        for i in range(len(states)):\n",
    "            new_map[states[i][0], states[i][1]] = 4\n",
    "            # plot velocity state as arrow\n",
    "            plt.arrow(states[i][1], states[i][0], states[i][3]/2, states[i][2]/2, width=0.1, head_width=0.5, head_length=0.5, color='b')\n",
    "            # plot qriver action on map arrow\n",
    "            plt.arrow(states[i][1], states[i][0], self.action_space[self.policy[states[i][0], states[i][1], states[i][2], states[i][3]]][1], self.action_space[self.policy[states[i][0], states[i][1], states[i][2], states[i][3]]][0], width=0.1, head_width=0.5, head_length=0.5, color='r')\n",
    "\n",
    "\n",
    "        plt.imshow(new_map)\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.show()\n",
    "        # save as eps\n",
    "        plt.savefig('../figure/fig_'+str(self.start_num)+'.eps', format='eps')\n",
    "        plt.close()\n",
    "        # reverse the returns\n",
    "        returns.reverse()\n",
    "        # update Q and policy\n",
    "        for i in range(len(states)):\n",
    "            if i == 0:\n",
    "                self.update_Q(states[i].copy(),\n",
    "                              self.action_space[self.policy[states[i][0], states[i][1], states[i][2], states[i][3]]],\n",
    "                              returns[i], alpha, gamma)\n",
    "            else:\n",
    "                self.update_Q(states[i],\n",
    "                              self.action_space[self.policy[states[i][0], states[i][1], states[i][2], states[i][3]]],\n",
    "                              returns[i], alpha, gamma)\n",
    "            self.update_policy(states[i])\n",
    "\n",
    "        self.epsilon *= self.gamma\n",
    "        # plot 9 plot in one plot subplot of Q\n",
    "        # for i in range(9):\n",
    "        #     plt.subplot(3, 3, i + 1)\n",
    "        #     plt.imshow(self.Q[:, :, 1, 1, i])\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25292faf9242e845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T10:34:08.894589Z",
     "start_time": "2023-12-03T10:34:08.879154Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main code \n",
    "racetrack = Racetrack(racetrack_map, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df7e6d5c15ec7b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run the car\n",
    "for i in range(1000):\n",
    "    racetrack.run_mont_carlo(0.1, 0.99)\n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "465900c03ad8945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T11:26:09.382470Z",
     "start_time": "2023-12-03T11:26:09.313941Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run racetrack use trained data\n",
    "def racetrack_run(racetrack_map, policy, Q, start_num):\n",
    "    racetrack = Racetrack(racetrack_map, start_num)\n",
    "    racetrack.epsilon = 0\n",
    "    racetrack.policy = policy\n",
    "    racetrack.Q = Q\n",
    "    racetrack.run_mont_carlo(0.1, 0.99, False)\n",
    "\n",
    "Q = np.load('Q.npy')\n",
    "policy = np.load('policy.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8a7056ad095f9bd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-03T14:39:42.158026Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(np.argwhere(racetrack_map == 2))):\n",
    "    racetrack_run(racetrack_map, policy, Q, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
